{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.144420800Z",
     "start_time": "2024-11-03T14:05:44.099244300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n",
    "from types import SimpleNamespace\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from virtual_fusion_accuracy import VirtualFusionAccuracy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.functional.classification import multiclass_calibration_error\n",
    "\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "from easydict import EasyDict\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.144420800Z",
     "start_time": "2024-11-03T14:05:44.099244300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Distortions\n",
    "Define the augmentations and distortions that are applied during training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "class Distortion:\n",
    "    def __init__(self, fn, lam, **kwargs):\n",
    "        self.fn = fn\n",
    "        self.lam = lam\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(seed=42)\n",
    "\n",
    "augMixAugmenter = v2.AugMix()\n",
    "\n",
    "distortions = {\n",
    "    'AugMix': [\n",
    "        Distortion(\n",
    "            lambda images:images,\n",
    "            1\n",
    "        ),\n",
    "        Distortion(\n",
    "            lambda images:augMixAugmenter(images),\n",
    "            0.85 # delta\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.170235100Z",
     "start_time": "2024-11-03T14:05:44.112861500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.170235100Z",
     "start_time": "2024-11-03T14:05:44.123922700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_root = \"C:/datasets/cifar10-image-folder\"\n",
    "data_c_root = \"C:/datasets/cifar-10-c\"\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.491, 0.482, 0.446],\n",
    "    std=[0.247, 0.243, 0.261]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "resize = 32\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((resize,resize), antialias='True'),\n",
    "    transforms.RandomCrop(resize, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.170235100Z",
     "start_time": "2024-11-03T14:05:44.134136700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a config object to store the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.170235100Z",
     "start_time": "2024-11-03T14:05:44.144420800Z"
    }
   },
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    distortion_p = 0.7,\n",
    "    train_batch_size = 1024,\n",
    "    train_num_epochs = 25,\n",
    "    train_optimizer_lr = 0.1,\n",
    "    train_lr_schedule_step_size = 25,\n",
    "    train_lr_schedule_gamma = 0.1,\n",
    "    evaluation_batch_size = 1024,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.170235100Z",
     "start_time": "2024-11-03T14:05:44.151361300Z"
    }
   },
   "outputs": [],
   "source": [
    "def LA_criterion(criterion, pred, y_a, y_b, lams):\n",
    "    return torch.mean(torch.mul(criterion(pred, y_a),lams) + torch.mul(criterion(pred, y_b),(1 - lams)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.280901Z",
     "start_time": "2024-11-03T14:05:44.160230500Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(\n",
    "    root=os.path.join(data_root, 'train'),\n",
    "    transform=train_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.286323300Z",
     "start_time": "2024-11-03T14:05:44.280901Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size= config.train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory = True,\n",
    "    drop_last = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, config):\n",
    "\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_model_params_path = os.path.join('checkpoints', f'LableAug_{config.train_num_epochs}_model_params.pt')\n",
    "\n",
    "    pbar = tqdm(total=num_epochs, unit='epoch')\n",
    "    pbar_batch = tqdm(total=len(train_dataset_loader), unit='batch')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        step = epoch + 1\n",
    "\n",
    "        # initialize metrics\n",
    "        acc_metric = VirtualFusionAccuracy()\n",
    "        acc_metric.to(device)\n",
    "\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        pbar_batch.reset()\n",
    "        # Iterate over data.\n",
    "        inputs_trained = False\n",
    "        for inputs, targets_a in train_dataset_loader:\n",
    "            for distortion_index, distortion_name in enumerate(distortions.keys()):\n",
    "                for distortion in distortions[distortion_name]:\n",
    "\n",
    "                    images = inputs\n",
    "                    p = torch.rand(1)\n",
    "                    if p < config.distortion_p :\n",
    "                        images = distortion.fn(images.to(device), **distortion.kwargs)\n",
    "                        targets_b = torch.ones_like(targets_a) * (original_num_classes + distortion_index)\n",
    "                        lams = torch.ones_like(targets_a) * distortion.lam\n",
    "                    else:\n",
    "                        if inputs_trained:\n",
    "                          continue\n",
    "                        inputs_trained = True\n",
    "                        targets_b = targets_a\n",
    "                        lams = torch.ones_like(targets_a)\n",
    "\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    images = normalize(images)\n",
    "                    targets_a = targets_a.to(device)\n",
    "                    targets_b = targets_b.to(device)\n",
    "                    lams = lams.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        outputs = model(images)\n",
    "                        loss = LA_criterion(criterion, outputs, targets_a, targets_b, lams)\n",
    "\n",
    "                        # backward + optimize\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    train_loss += loss.item()\n",
    "                    total += images.size(0)\n",
    "\n",
    "                    acc = acc_metric(outputs,  targets_a, targets_b, lams)\n",
    "\n",
    "            pbar_batch.update(1)\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = train_loss / total\n",
    "        epoch_acc  = acc_metric.compute()\n",
    "        print(f' Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        if best_acc<epoch_acc:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': loss,\n",
    "                'config': config\n",
    "            }, best_model_params_path)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar_batch.close()\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "    # load best model\n",
    "    checkpoint = torch.load(best_model_params_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.295746100Z",
     "start_time": "2024-11-03T14:05:44.289227600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### cosine annealing schedule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_lr(step, total_steps, lr_max, lr_min):\n",
    "    \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:44.302959100Z",
     "start_time": "2024-11-03T14:05:44.295746100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    original_num_classes = len(train_dataset.classes)\n",
    "    num_classes = original_num_classes + len(distortions.keys())\n",
    "\n",
    "    net  = wide_resnet50_2(weights= Wide_ResNet50_2_Weights.DEFAULT)\n",
    "\n",
    "    # for param in net.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
    "\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr= config.train_optimizer_lr, momentum=0.9)\n",
    "\n",
    "    exp_lr_scheduler = lr_scheduler.LambdaLR(\n",
    "        optimizer,\n",
    "        lr_lambda=lambda step: get_lr(\n",
    "            step,\n",
    "            config.train_num_epochs,\n",
    "            1,  # lr_lambda computes multiplicative factor\n",
    "            1e-6 / config.train_optimizer_lr)\n",
    "    )\n",
    "\n",
    "    net = train_model(net, criterion, optimizer, exp_lr_scheduler, config.train_num_epochs, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:12:59.352993600Z",
     "start_time": "2024-11-03T14:12:59.334382400Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_performance(model, criterion, distortion_name):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    accs = []\n",
    "\n",
    "\n",
    "    for severity in range(1, 6):\n",
    "        if severity>1 and distortion_name=='original':\n",
    "            continue\n",
    "        distorted_dataset = datasets.ImageFolder(\n",
    "            root=os.path.join(data_c_root, distortion_name, str(severity)),\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((resize,resize), antialias='True'),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        distorted_dataset_loader = torch.utils.data.DataLoader(\n",
    "            distorted_dataset,\n",
    "            batch_size= config.evaluation_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            drop_last = True,\n",
    "        )\n",
    "\n",
    "        eval_loss = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        # initialize metric\n",
    "        acc_metric = Accuracy(task=\"multiclass\", num_classes=original_num_classes)\n",
    "        acc_metric.to(device)\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(distorted_dataset_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                loss = criterion(output,target)\n",
    "\n",
    "            # create a mask for indices less than the number of actual classes\n",
    "            filter_mask = torch.arange(output.size(1)) < original_num_classes\n",
    "\n",
    "            # apply filter\n",
    "            filtered_output = output[:, filter_mask]\n",
    "\n",
    "            _, pred = torch.max(filtered_output, 1)\n",
    "\n",
    "            # statistics\n",
    "            eval_loss += torch.mean(loss).item()\n",
    "            total += data.size(0)\n",
    "            acc = acc_metric(pred,  target)\n",
    "            err = 1 - acc\n",
    "\n",
    "\n",
    "        acc =  acc_metric.compute()\n",
    "        err = 1 - acc\n",
    "        accs.append(acc)\n",
    "\n",
    "\n",
    "    model.train(mode=was_training)\n",
    "    mean_acc = torch.mean(torch.tensor(accs).detach().cpu())\n",
    "    mean_err = 1 - mean_acc\n",
    "\n",
    "    return mean_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet-C evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T14:22:25.324163400Z",
     "start_time": "2024-11-03T14:12:59.334382400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distortion: gaussian_noise   | CE (unnormalized) (%): 21.82\n",
      "Distortion: shot_noise       | CE (unnormalized) (%): 19.24\n",
      "Distortion: impulse_noise    | CE (unnormalized) (%): 29.33\n",
      "Distortion: defocus_blur     | CE (unnormalized) (%): 12.24\n",
      "Distortion: glass_blur       | CE (unnormalized) (%): 29.82\n",
      "Distortion: motion_blur      | CE (unnormalized) (%): 17.21\n",
      "Distortion: zoom_blur        | CE (unnormalized) (%): 15.45\n",
      "Distortion: snow             | CE (unnormalized) (%): 17.72\n",
      "Distortion: frost            | CE (unnormalized) (%): 16.85\n",
      "Distortion: fog              | CE (unnormalized) (%): 17.25\n",
      "Distortion: brightness       | CE (unnormalized) (%): 9.84\n",
      "Distortion: contrast         | CE (unnormalized) (%): 21.67\n",
      "Distortion: elastic_transform  | CE (unnormalized) (%): 14.60\n",
      "Distortion: pixelate         | CE (unnormalized) (%): 17.08\n",
      "Distortion: jpeg_compression  | CE (unnormalized) (%): 15.19\n",
      "Distortion: original         | CE (unnormalized) (%): 8.57\n",
      "mCE (unnormalized by ResNet errors) (%): 18.35\n"
     ]
    }
   ],
   "source": [
    "distortions_c = [\n",
    "    'gaussian_noise',\n",
    "    'shot_noise', 'impulse_noise',\n",
    "    'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur',\n",
    "    'snow', 'frost', 'fog', 'brightness',\n",
    "    'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression',\n",
    "    'original',\n",
    "]\n",
    "\n",
    "error_rates = []\n",
    "for distortion_name in distortions_c:\n",
    "    rate = show_performance(net, criterion, distortion_name)\n",
    "    error_rates.append(rate)\n",
    "    print('Distortion: {:15s}  | CE (unnormalized) (%): {:.2f}'.format(distortion_name, 100 * rate))\n",
    "\n",
    "\n",
    "error_rates.pop()  # to remove original for distortions_c\n",
    "mCE = 100 * np.mean(error_rates)\n",
    "print('mCE (unnormalized by ResNet errors) (%): {:.2f}'.format(mCE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.03\n",
      "Error on FGM adversarial examples (%): 27.138\n",
      "Error on PGD adversarial examples (%): 56.999\n",
      "Epsilon: 0.3\n",
      "Error on FGM adversarial examples (%): 46.571\n",
      "Error on PGD adversarial examples (%): 82.151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(data_root, 'test'),\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((resize,resize), antialias='True'),\n",
    "        transforms.ToTensor(),\n",
    "        normalize ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=config.evaluation_batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "eps_values = [0.03, 0.3]\n",
    "error_reports = {}\n",
    "\n",
    "net.eval()\n",
    "\n",
    "for eps in eps_values:\n",
    "    report = EasyDict(nb_test=0, correct=0, correct_fgm=0, correct_pgd=0)\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_fgm = fast_gradient_method(net, x, eps, np.inf)\n",
    "        x_pgd = projected_gradient_descent(net, x, eps, 0.01, 40, np.inf)\n",
    "\n",
    "\n",
    "        filter_mask = torch.arange(num_classes) < original_num_classes\n",
    "\n",
    "        _, y_pred = net(x)[:, filter_mask].max(1)  # model prediction on clean examples\n",
    "        _, y_pred_fgm = net(x_fgm)[:, filter_mask].max(1)  # model prediction on FGM adversarial examples\n",
    "        _, y_pred_pgd = net(x_pgd)[:, filter_mask].max(1)\n",
    "\n",
    "        report.nb_test += y.size(0)\n",
    "        report.correct_fgm += y_pred_fgm.eq(y).sum().item()\n",
    "        report.correct_pgd += y_pred_pgd.eq(y).sum().item()\n",
    "\n",
    "    fgm_acc = report.correct_fgm / report.nb_test\n",
    "    pgd_acc = report.correct_pgd / report.nb_test\n",
    "\n",
    "    fgm_error = 1 - fgm_acc\n",
    "    pgd_error = 1 - pgd_acc\n",
    "\n",
    "    error_reports[eps] = {'FGM': fgm_error, 'PGD': pgd_error}\n",
    "\n",
    "for eps, errors in error_reports.items():\n",
    "    print(f\"Epsilon: {eps}\")\n",
    "    print(\"Error on FGM adversarial examples (%): {:.3f}\".format(errors['FGM'] * 100.0))\n",
    "    print(\"Error on PGD adversarial examples (%): {:.3f}\".format(errors['PGD'] * 100.0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:24:06.384023800Z",
     "start_time": "2024-11-03T14:22:25.330144200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidences=0.961664617061615   accuracies=0.9142795205116272\n",
      "confidences=0.961664617061615   accuracies=0.9142795205116272\n",
      "the expected calibration error is: 4.8696489334106445\n",
      "the root mean squared calibration error is: 8.90273666381836\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ps = [] ; ls=[]\n",
    "accuracies= []\n",
    "acc_metric = Accuracy(task=\"multiclass\", num_classes=original_num_classes)\n",
    "acc_metric.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (inputs, labels) in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        filter_mask = torch.arange(outputs.size(1)) < original_num_classes\n",
    "        filtered_output = outputs[:, filter_mask]\n",
    "        _, pred = torch.max(filtered_output, 1)\n",
    "        acc = acc_metric(pred,  labels)\n",
    "\n",
    "        ps.append(filtered_output)\n",
    "        ls.append(labels)\n",
    "    acc =  acc_metric.compute()\n",
    "    err = 1 - acc\n",
    "    accuracies.append(acc)\n",
    "\n",
    "mean_acc = torch.mean(torch.tensor(accuracies).detach().cpu())\n",
    "mean_err = 1 - mean_acc\n",
    "\n",
    "ps = torch.cat(ps, dim=0)\n",
    "ls = torch.cat(ls, dim=0)\n",
    "\n",
    "ECE = multiclass_calibration_error(ps, ls, num_classes=original_num_classes, n_bins=100, norm='l1')*100\n",
    "RMS = multiclass_calibration_error(ps, ls, num_classes=original_num_classes, n_bins=100, norm='l2')*100\n",
    "\n",
    "\n",
    "print(f'the expected calibration error is: {ECE}')\n",
    "print(f'the root mean squared calibration error is: {RMS}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:24:12.595457700Z",
     "start_time": "2024-11-03T14:24:06.384023800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
